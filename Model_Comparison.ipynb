{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912bcab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn imports for modeling and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd0ed7",
   "metadata": {},
   "source": [
    "### Load the Cleaned Dataset\n",
    "First, let's load the `heart_clean.csv` file and inspect the first few rows to understand the structure and columns. This helps confirm the data is ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704878dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>...</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ExerciseAngina_N</th>\n",
       "      <th>ExerciseAngina_Y</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "      <th>HeartDisease_0</th>\n",
       "      <th>HeartDisease_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  Sex_F  Sex_M  \\\n",
       "0  40.0      140.0        289.0        0.0  172.0      0.0    0.0    1.0   \n",
       "1  49.0      160.0        180.0        0.0  156.0      1.0    1.0    0.0   \n",
       "2  37.0      130.0        283.0        0.0   98.0      0.0    0.0    1.0   \n",
       "3  48.0      138.0        214.0        0.0  108.0      1.5    1.0    0.0   \n",
       "4  54.0      150.0        195.0        0.0  122.0      0.0    0.0    1.0   \n",
       "\n",
       "   ChestPainType_ASY  ChestPainType_ATA  ...  RestingECG_LVH  \\\n",
       "0                0.0                1.0  ...             0.0   \n",
       "1                0.0                0.0  ...             0.0   \n",
       "2                0.0                1.0  ...             0.0   \n",
       "3                1.0                0.0  ...             0.0   \n",
       "4                0.0                0.0  ...             0.0   \n",
       "\n",
       "   RestingECG_Normal  RestingECG_ST  ExerciseAngina_N  ExerciseAngina_Y  \\\n",
       "0                1.0            0.0               1.0               0.0   \n",
       "1                1.0            0.0               1.0               0.0   \n",
       "2                0.0            1.0               1.0               0.0   \n",
       "3                1.0            0.0               0.0               1.0   \n",
       "4                1.0            0.0               1.0               0.0   \n",
       "\n",
       "   ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  HeartDisease_0  HeartDisease_1  \n",
       "0            0.0            0.0          1.0             1.0             0.0  \n",
       "1            0.0            1.0          0.0             0.0             1.0  \n",
       "2            0.0            0.0          1.0             1.0             0.0  \n",
       "3            0.0            1.0          0.0             0.0             1.0  \n",
       "4            0.0            0.0          1.0             1.0             0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned dataset\n",
    "df = pd.read_csv(\"heart_clean.csv\")\n",
    "\n",
    "# Show first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8887c8f2",
   "metadata": {},
   "source": [
    "### Define Features and Target\n",
    "We'll now define our input features (X) and the target variable (y). For this analysis, we’ll use:\n",
    "- `Age` and `Cholesterol` as numerical features\n",
    "- `Sex_F` as a categorical feature  \n",
    "Our target variable will be `HeartDisease_1`, which indicates presence of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9a819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    Age  Cholesterol  Sex_F\n",
       " 0  40.0        289.0    0.0\n",
       " 1  49.0        180.0    1.0\n",
       " 2  37.0        283.0    0.0\n",
       " 3  48.0        214.0    1.0\n",
       " 4  54.0        195.0    0.0,\n",
       " 0    0.0\n",
       " 1    1.0\n",
       " 2    0.0\n",
       " 3    1.0\n",
       " 4    0.0\n",
       " Name: HeartDisease_1, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define input features (X) and target variable (y)\n",
    "X = df[[\"Age\", \"Cholesterol\", \"Sex_F\"]]\n",
    "y = df[\"HeartDisease_1\"]\n",
    "\n",
    "# Preview the selected features and target\n",
    "X.head(), y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c36e59",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "To evaluate our models fairly, we split the dataset into a training set (80%) and a testing set (20%) using `train_test_split` from `sklearn.model_selection`. This helps us ensure that the models don’t just memorize the data but actually learn patterns that generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfad54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((733, 3), (184, 3), (733,), (184,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Show the shapes of the resulting datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce56506",
   "metadata": {},
   "source": [
    "### Train Logistic Regression Model\n",
    "\n",
    "We'll start by training a **Logistic Regression** model using the training data. This model is a popular choice for binary classification tasks, such as predicting the presence or absence of heart disease.\n",
    "\n",
    "We'll fit the model on `X_train` and `y_train`, then make predictions on the test set `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43be6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted  Actual\n",
       "0        0.0     0.0\n",
       "1        1.0     1.0\n",
       "2        1.0     1.0\n",
       "3        1.0     1.0\n",
       "4        1.0     0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "# Show first 5 predictions vs actual labels\n",
    "pd.DataFrame({\n",
    "    'Predicted': y_pred_log[:5],\n",
    "    'Actual': y_test[:5].values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda83445",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "The table above shows the **first five predictions** made by the Logistic Regression model on the test dataset. It compares the predicted labels (`Predicted`) with the actual labels (`Actual`):\n",
    "- The model **correctly predicted** the outcome for 4 out of 5 samples.\n",
    "- In row 4, the model predicted `1.0` (presence of heart disease), while the actual value was `0.0` (no heart disease). This is an example of a **false positive**.\n",
    "\n",
    "This preliminary result suggests the model is performing reasonably well. However, to properly evaluate its effectiveness, we’ll need to analyze more detailed metrics such as **accuracy**, **precision**, **recall**, and **F1-score** in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db9e39",
   "metadata": {},
   "source": [
    "### Evaluate the Logistic Regression Model\n",
    "\n",
    "To understand how well our model performs, we’ll evaluate it using the following metrics:\n",
    "\n",
    "- **Accuracy**: Overall correctness of the model.\n",
    "- **Precision**: Correct positive predictions out of total predicted positives.\n",
    "- **Recall**: Correct positive predictions out of actual positives.\n",
    "- **F1-score**: Harmonic mean of precision and recall.\n",
    "- **Confusion Matrix**: A table that summarizes the true vs. predicted classifications.\n",
    "\n",
    "These metrics give us a well-rounded view of how well the model detects heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe1220f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Precision: 0.73\n",
      "Recall: 0.79\n",
      "F1 Score: 0.76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39 33]\n",
      " [23 89]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_log)\n",
    "precision = precision_score(y_test, y_pred_log)\n",
    "recall = recall_score(y_test, y_pred_log)\n",
    "f1 = f1_score(y_test, y_pred_log)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_log)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", round(accuracy, 2))\n",
    "print(\"Precision:\", round(precision, 2))\n",
    "print(\"Recall:\", round(recall, 2))\n",
    "print(\"F1 Score:\", round(f1, 2))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f436d01",
   "metadata": {},
   "source": [
    "#### Evaluation Results for Logistic Regression Model\n",
    "\n",
    "The logistic regression model was evaluated using accuracy, precision, recall, and F1 score. Here’s what the results tell us:\n",
    "\n",
    "- **Accuracy (0.70)**: The model correctly predicted 70% of the test data.\n",
    "- **Precision (0.73)**: When the model predicted that a patient has heart disease, it was correct 73% of the time.\n",
    "- **Recall (0.79)**: Out of all patients who actually had heart disease, the model correctly identified 79% of them.\n",
    "- **F1 Score (0.76)**: This is the harmonic mean of precision and recall, providing a balanced performance measure.\n",
    "\n",
    "#### Confusion Matrix:\n",
    "[[39 33]\n",
    "[23 89]]\n",
    "\n",
    "- **True Negatives (39)**: Correctly predicted as not having heart disease.\n",
    "- **False Positives (33)**: Incorrectly predicted as having heart disease.\n",
    "- **False Negatives (23)**: Missed cases where heart disease was actually present.\n",
    "- **True Positives (89)**: Correctly identified heart disease cases.\n",
    "\n",
    "#### Conclusion:\n",
    "The model is effective at identifying most heart disease cases (high recall), making it useful for early detection. However, its moderate precision means some healthy individuals may be flagged incorrectly. In healthcare, this trade-off can be acceptable, as it's better to catch potential risks early and follow up with proper medical evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e44c9",
   "metadata": {},
   "source": [
    "### Train K-Nearest Neighbors (KNN) Model\n",
    "\n",
    "Now we train a K-Nearest Neighbors (KNN) classifier. KNN is a non-parametric, instance-based learning algorithm that classifies new data points based on the majority label among their nearest neighbors. It's especially effective for datasets that are not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e76f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted  Actual\n",
       "0        0.0     0.0\n",
       "1        0.0     1.0\n",
       "2        1.0     1.0\n",
       "3        1.0     1.0\n",
       "4        0.0     0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize KNN with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Show first 5 predictions vs actual labels\n",
    "pd.DataFrame({\n",
    "    'Predicted': y_pred_knn[:5],\n",
    "    'Actual': y_test[:5].values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a580b4",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "The table above displays the **first five predictions** made by the K-Nearest Neighbors (KNN) model on the test dataset, comparing the predicted labels (`Predicted`) with the actual labels (`Actual`):\n",
    "- The model **correctly predicted** 4 out of 5 samples.\n",
    "- In row 1, the model predicted `0.0` (no heart disease), but the actual label was `1.0` (presence of heart disease) which is a **false negative**.\n",
    "\n",
    "Overall, these initial predictions show promising performance. But, we'll need to assess the model’s full effectiveness using evaluation metrics like **accuracy**, **precision**, **recall**, and **F1-score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7696c",
   "metadata": {},
   "source": [
    "### Evaluate the KNN Model\n",
    "\n",
    "We evaluate the KNN model using accuracy, precision, recall, F1-score, and the confusion matrix to understand its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea5f501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.65\n",
      "KNN Precision: 0.69\n",
      "KNN Recall: 0.75\n",
      "KNN F1 Score: 0.72\n",
      "KNN Confusion Matrix:\n",
      " [[35 37]\n",
      " [28 84]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Print results\n",
    "print(\"KNN Accuracy:\", round(accuracy_knn, 2))\n",
    "print(\"KNN Precision:\", round(precision_knn, 2))\n",
    "print(\"KNN Recall:\", round(recall_knn, 2))\n",
    "print(\"KNN F1 Score:\", round(f1_knn, 2))\n",
    "print(\"KNN Confusion Matrix:\\n\", conf_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7dc4c",
   "metadata": {},
   "source": [
    "#### Evaluation Results for K-Nearest Neighbors (KNN) Model\n",
    "\n",
    "The KNN model was evaluated using accuracy, precision, recall, and F1 score. Here's what the results tell us:\n",
    "\n",
    "- **Accuracy (0.65)**: The model correctly predicted ~65% of the test data.\n",
    "- **Precision (0.69)**: When the model predicted that a patient has heart disease, it was correct ~69% of the time.\n",
    "- **Recall (0.75)**: Out of all patients who actually had heart disease, the model correctly identified 75% of them.\n",
    "- **F1 Score (0.72)**: A balanced measure combining precision and recall.\n",
    "\n",
    "#### Confusion Matrix:\n",
    "[[35 37]\n",
    "[28 84]]\n",
    "\n",
    "- **True Negatives (35)**: Correctly predicted as not having heart disease.\n",
    "- **False Positives (37)**: Incorrectly predicted as having heart disease.\n",
    "- **False Negatives (28)**: Missed cases where heart disease was actually present.\n",
    "- **True Positives (84)**: Correctly identified heart disease cases.\n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "The KNN model shows reasonably good recall and F1 score, indicating it can detect many true heart disease cases. However, the number of false positives (37) is relatively high, which could lead to unnecessary concern or follow-up tests. In healthcare, this trade-off might still be acceptable to avoid missing critical diagnoses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76427d54",
   "metadata": {},
   "source": [
    "### Train Naive Bayes Model\n",
    "Here, we train a Naive Bayes model on the same training data used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c95afb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted  Actual\n",
       "0        0.0     0.0\n",
       "1        0.0     1.0\n",
       "2        1.0     1.0\n",
       "3        1.0     1.0\n",
       "4        1.0     0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Display first 5 predictions vs actual\n",
    "pd.DataFrame({\n",
    "    'Predicted': y_pred_nb[:5],\n",
    "    'Actual': y_test[:5].values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88747608",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "The table above displays the **first five predictions** made by the Naive Bayes model:\n",
    "- The model correctly predicted 3 out of 5 samples.\n",
    "- Row 1 shows a **false negative** (predicted `0.0`, actual `1.0`), and\n",
    "- Row 4 shows a **false positive** (predicted `1.0`, actual `0.0`).\n",
    "\n",
    "These early results indicate that while the model is capturing most of the patterns correctly, it still makes some classification errors. We'll assess its full performance in the next step using evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846465a",
   "metadata": {},
   "source": [
    "### Evaluate the Naive Bayes Model\n",
    "\n",
    "We evaluate the Naive Bayes model using accuracy, precision, recall, F1-score, and the confusion matrix to understand its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7d87f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7\n",
      "Naive Bayes Precision: 0.72\n",
      "Naive Bayes Recall: 0.83\n",
      "Naive Bayes F1 Score: 0.77\n",
      "Naive Bayes Confusion Matrix:\n",
      " [[35 37]\n",
      " [19 93]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Evaluate model performance\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "nb_precision = precision_score(y_test, y_pred_nb)\n",
    "nb_recall = recall_score(y_test, y_pred_nb)\n",
    "nb_f1 = f1_score(y_test, y_pred_nb)\n",
    "nb_cm = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "# Print the results\n",
    "print(\"Naive Bayes Accuracy:\", round(nb_accuracy, 2))\n",
    "print(\"Naive Bayes Precision:\", round(nb_precision, 2))\n",
    "print(\"Naive Bayes Recall:\", round(nb_recall, 2))\n",
    "print(\"Naive Bayes F1 Score:\", round(nb_f1, 2))\n",
    "print(\"Naive Bayes Confusion Matrix:\\n\", nb_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f707c0fb",
   "metadata": {},
   "source": [
    "#### Evaluation Results for Naive Bayes Model\n",
    "\n",
    "The Naive Bayes model was evaluated using accuracy, precision, recall, and F1 score. Here's what the results tell us:\n",
    "\n",
    "- **Accuracy (0.70)**: The model correctly predicted 70% of the test data.\n",
    "- **Precision (0.72)**: When the model predicted that a patient has heart disease, it was correct 72% of the time.\n",
    "- **Recall (0.83)**: Out of all patients who actually had heart disease, the model correctly identified 83% of them.\n",
    "- **F1 Score (0.77)**: A balanced measure combining precision and recall.\n",
    "\n",
    "#### Confusion Matrix:\n",
    "[[35 37]\n",
    "[19 93]]\n",
    "\n",
    "- **True Negatives (35)**: Correctly predicted as not having heart disease.  \n",
    "- **False Positives (37)**: Incorrectly predicted as having heart disease.  \n",
    "- **False Negatives (19)**: Missed cases where heart disease was actually present.  \n",
    "- **True Positives (93)**: Correctly identified heart disease cases.\n",
    "\n",
    "#### Conclusion:\n",
    "The Naive Bayes model demonstrates strong recall and F1 score, making it effective at identifying patients with heart disease. Although it still has a notable number of false positives (37), the reduced false negatives (19) make it suitable for healthcare settings where catching true cases is a priority."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f4db0",
   "metadata": {},
   "source": [
    "### Train Support Vector Machine (SVM) Model\n",
    "In this section, we train a Support Vector Machine (SVM) model to classify whether a patient has heart disease. SVM is a powerful supervised learning algorithm that attempts to find the optimal hyperplane that separates the classes with the largest margin. We’ll use the same training data as with our previous models to ensure a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04223ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted  Actual\n",
       "0        0.0     0.0\n",
       "1        1.0     1.0\n",
       "2        1.0     1.0\n",
       "3        1.0     1.0\n",
       "4        1.0     0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear')  # Using linear kernel for interpretability\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Show first 5 predictions vs actual labels\n",
    "pd.DataFrame({\n",
    "    'Predicted': y_pred_svm[:5],\n",
    "    'Actual': y_test[:5].values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6423d82",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "The table above shows the **first five predictions** made by the SVM model on the test dataset. It compares the predicted labels (`Predicted`) with the actual labels (`Actual`):\n",
    "- The model **correctly predicted** the outcome for 4 out of 5 samples.\n",
    "- In row 4, the model predicted `1.0` (presence of heart disease), while the actual value was `0.0` (no heart disease). This is an example of a **false positive**.\n",
    "\n",
    "Initial predictions suggest that the SVM model is performing well, but a deeper evaluation with performance metrics is needed to validate its effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03f455",
   "metadata": {},
   "source": [
    "### Evaluate the SVM Model\n",
    "\n",
    "We evaluate the SVM model using accuracy, precision, recall, F1-score, and the confusion matrix to understand its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a8d164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.67\n",
      "SVM Precision: 0.67\n",
      "SVM Recall: 0.9\n",
      "SVM F1 Score: 0.77\n",
      "SVM Confusion Matrix:\n",
      " [[ 22  50]\n",
      " [ 11 101]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "precision = precision_score(y_test, y_pred_svm)\n",
    "recall = recall_score(y_test, y_pred_svm)\n",
    "f1 = f1_score(y_test, y_pred_svm)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Print results\n",
    "print(\"SVM Accuracy:\", round(accuracy, 2))\n",
    "print(\"SVM Precision:\", round(precision, 2))\n",
    "print(\"SVM Recall:\", round(recall, 2))\n",
    "print(\"SVM F1 Score:\", round(f1, 2))\n",
    "print(\"SVM Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0720dcf",
   "metadata": {},
   "source": [
    "#### Evaluation Results for Support Vector Machine (SVM) Model\n",
    "\n",
    "The SVM model was evaluated using accuracy, precision, recall, and F1 score. Here's what the results indicate:\n",
    "\n",
    "- **Accuracy (0.67)**: The model correctly predicted 67% of the test cases.\n",
    "- **Precision (0.67)**: When the model predicted the presence of heart disease, it was correct 67% of the time.\n",
    "- **Recall (0.90)**: Out of all actual heart disease cases, the model successfully identified 90% of them.\n",
    "- **F1 Score (0.77)**: A strong balance between precision and recall.\n",
    "\n",
    "#### Confusion Matrix:\n",
    "[[22 50]\n",
    "[11 101]]\n",
    "\n",
    "- **True Negatives (22)**: Correctly predicted as not having heart disease.\n",
    "- **False Positives (50)**: Incorrectly predicted as having heart disease.\n",
    "- **False Negatives (11)**: Missed actual cases of heart disease.\n",
    "- **True Positives (101)**: Correctly identified heart disease cases.\n",
    "\n",
    "#### Conclusion:\n",
    "The SVM model demonstrates excellent recall, meaning it’s highly effective at catching most heart disease cases. However, it has a high false positive rate, which could result in overdiagnosis. This may still be acceptable in medical settings where failing to detect illness is riskier than false alarms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53df71bf",
   "metadata": {},
   "source": [
    "## Final Model Comparison: Naive Bayes vs Support Vector Machine (SVM)\n",
    "\n",
    "After evaluating all four models, we selected **Naive Bayes** and **SVM** for final comparison based on their strong performance - particularly in **recall** and **F1 score**, which are critical in healthcare where identifying true cases is vital.\n",
    "\n",
    "### Comparison Table\n",
    "\n",
    "| Metric      | Naive Bayes | SVM     |\n",
    "|-------------|-------------|---------|\n",
    "| Accuracy    | 0.70        | 0.67    |\n",
    "| Precision   | 0.72        | 0.67    |\n",
    "| Recall      | 0.83        | 0.90    |\n",
    "| F1 Score    | 0.77        | 0.77    |\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **SVM achieved the highest recall (0.90)** - making it more effective at detecting patients with heart disease.\n",
    "- **Naive Bayes offers higher precision (0.72)** - meaning fewer false positives.\n",
    "- **Both models share the same F1 score (0.77)** - showing a balanced overall performance.\n",
    "\n",
    "### Final Takeaway\n",
    "\n",
    "While both models perform well, **SVM holds a slight advantage** due to its higher recall which is a critical factor in medical diagnosis where missing a positive case can be costly. That said, **Naive Bayes** is still a strong alternative when the goal is to minimize false alarms and maintain simpler model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d9b53",
   "metadata": {},
   "source": [
    "## Evaluation Metrics Explained\n",
    "\n",
    "To evaluate our models, we used four primary metrics: **Accuracy**, **Precision**, **Recall**, and **F1 Score**.\n",
    "\n",
    "### 1. Accuracy\n",
    "The proportion of total correct predictions made by the model.\n",
    "\n",
    "**Formula:**  \n",
    "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "- **TP (True Positives):** Correctly predicted heart disease cases.  \n",
    "- **TN (True Negatives):** Correctly predicted non-disease cases.  \n",
    "- **FP (False Positives):** Incorrectly predicted heart disease (but actually healthy).  \n",
    "- **FN (False Negatives):** Missed actual heart disease cases.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Precision\n",
    "Out of all the predicted positive cases, how many were actually positive.\n",
    "\n",
    "**Formula:**  \n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "- High precision means fewer false alarms.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Recall (Sensitivity)\n",
    "Out of all actual positive cases, how many the model was able to catch.\n",
    "\n",
    "**Formula:**  \n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "- High recall means fewer missed disease cases which is critical in healthcare.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. F1 Score\n",
    "Harmonic mean of precision and recall. It balances both metrics.\n",
    "\n",
    "**Formula:**  \n",
    "F1 Score = 2 × (Precision × Recall) / (Precision + Recall)\n",
    "\n",
    "- Useful when there's an uneven class distribution or when both false positives and false negatives matter.\n",
    "\n",
    "---\n",
    "\n",
    "These metrics help us evaluate how well our models perform and which one is more reliable for **heart disease detection**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
